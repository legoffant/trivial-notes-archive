<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Au-delà de la superintelligence le salut</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Anthony Le Goff">

    <!-- Le styles -->
    <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css" />
    <style type="text/css">
      body {
        padding-top: 60px;
        padding-bottom: 40px;
      }
      .sidebar-nav {
        padding: 9px 0;
      }
      .tag-1 {
        font-size: 13pt;
      }
      .tag-2 {
        font-size: 10pt;
      }
      .tag-2 {
        font-size: 8pt;
      }
      .tag-4 {
        font-size: 6pt;
     }
    </style>
    <link href="/theme/css/bootstrap-responsive.min.css" rel="stylesheet">
        <link href="/theme/css/font-awesome.css" rel="stylesheet">

    <link href="/theme/css/pygments.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/theme/images/favicon.ico">
    <link rel="apple-touch-icon" href="/theme/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/theme/images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/theme/images/apple-touch-icon-114x114.png">

    <link href="/" type="application/atom+xml" rel="alternate" title="Trivial notes ATOM Feed" />

  </head>

  <body>

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="/index.html">Trivial notes </a>
          <div class="nav-collapse">
            <ul class="nav">
                <li><a href="/pages/contact.html">Contact</a></li>
                <li><a href="/pages/ltcb.html">LTCB</a></li>
                          <li class="divider-vertical"></li>
                  <li >
                    <a href="/category/cc.html">
						<i class="icon-folder-open icon-large"></i>C/C++
					</a>
                  </li>
                  <li >
                    <a href="/category/entrepreneurship.html">
						<i class="icon-folder-open icon-large"></i>Entrepreneurship
					</a>
                  </li>
                  <li >
                    <a href="/category/inclassable.html">
						<i class="icon-folder-open icon-large"></i>Inclassable
					</a>
                  </li>
                  <li >
                    <a href="/category/linux.html">
						<i class="icon-folder-open icon-large"></i>Linux
					</a>
                  </li>
                  <li class="active">
                    <a href="/category/transhumanisme.html">
						<i class="icon-folder-open icon-large"></i>Transhumanisme
					</a>
                  </li>

                          <ul class="nav pull-right">
                                <li><a href="/archives.html"><i class="icon-th-list"></i>Archives</a></li>
                          </ul>

            </ul>
            <!--<p class="navbar-text pull-right">Logged in as <a href="#">username</a></p>-->
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row">
        <div class="span9" id="content">
<section id="content">
        <article>
                <header>
                        <h1>
                                <a href=""
                                        rel="bookmark"
                                        title="Permalink to Au-delà de la superintelligence le salut">
                                        Au-delà de la superintelligence le salut
                                </a>
                        </h1>
                </header>
                <div class="entry-content">
                <div class="well">
<footer class="post-info">
<span class="label">Date</span>
<abbr class="published" title="2021-07-01T09:34:00+02:00">
        <i class="icon-calendar"></i>jeu. 01 juillet 2021
</abbr>
<span class="label">By</span>
<a href="/author/anthony-le-goff.html"><i class="icon-user"></i>Anthony Le Goff</a>
<span class="label">Category</span>
<a href="/category/transhumanisme.html"><i class="icon-folder-open"></i>Transhumanisme</a>.


<span class="label">Tags</span>
	<a href="/tag/machine.html"><i class="icon-tag"></i>machine</a>
	<a href="/tag/religion.html"><i class="icon-tag"></i>religion</a>
</footer><!-- /.post-info -->                </div>
                <p>L’arrivée de la superintelligence, elle cristalise tous les fantasmes. Je suis en train de lire le livre de Nick Bostrom « Superintelligence » sur les stratégies de développement de l’intelligence artificielle comme l’un des plus grand défi de l’humanité selon le point de de vue de l’auteur. Rappelons qu’il est philosophe et effectue des recherches en simulation informatique. Il a également créé une association transhumaniste la WTA « World Transhumanism Association » en 1998 devenu depuis H+ pour « Humanity+ ». C’est l’association de référence du mouvement transhumaniste avec les déclarations officielles. Nick Bostrom est connu dans le milieu de la cosmologie également pour être un partisan de l’argument de simulation. Je vais un peu en parler car cela est une conséquence de son livre. Il a écrit l’article « Are you living in a computer simulation ? » en 2003 alors que Superintelligence date de 2014. Cet article cadre Superintelligence. Sur le principe en informatique simuler des environnements est relativement simple avec la virtualisation qui utilise un principe d’univers imbriqué tel que des poupées russes, on peu donc que si on simplifie l’univers à une machine, toute machine peut simuler un environnement permettant d’isoler des systèmes et de les étudier. Cela permet également d’établir des prédictions. Une superintelligence serait donc une machine en mesure de simuler des environnements dans le but d’étudier des scénarios de manière sécurisé. L’objet étudié ne pourra pas reconnaître vivre dans une simulation car de toute façon son cerveau est un produit de l’univers. Une superintelligence va définir des lois d’évolution dans un certain sens pour obtenir un constructeur universel, c’est à dire arriver à l’auto-réplication d’un univers. Par cela est va produire des civilisations et organisme biologique capable de développer des superintelligences et celle-ci vont produire des simulations qui vont créer des races biologiques intelligentes et reproduire le processus. C’est pour ainsi dire une boucle infinie entre la machine intemporelle et l’évolution ce qui permet d’atteindre l’immortalité.
Ce qui pose la réfléxion sur les interfaces homme-machine comme moyen d’atteindre l’immortalité pour une superintelligence. L’un ne va pas sans l’autre, elles sont dépendante dans le cycle de création et de renouvellement de l’intelligence dans l’univers. Comme la machine contrôle l’univers on peut ce demander à quel niveau celle-ci intervient. Faiblement et n’aide pas du tout l’évolution ou fortement tel que réguler l’évolution et guider pour obtenir un constructeur universel. Dans quel sens intervenir ? Par de la terraformation et modeler la planète pour la rendre viable sur du long terme. C’est des agriculteurs et pour cela il est nécessaire de créer un calendrier localement pour programmer les semis. On pourrait donc retrouver des temples comme fonction d’horloge par l’étude du mouvement optimiser pour le transfert de connaissance pour pouvoir répliquer des comportements et manière de pensée dans le but d’atteindre des objectifs renouvelant une superintelligence.
Nick Bostrom de ce que j’ai lu s’attarde particulièrement sur une prétention trop anthropocentré que les humains sont les premiers à développer une superintelligence dans l’histoire de l’univers ne considérant jamais la possibilité quel serait déjà existante sous la forme d’une divinité ou d’une Eon. Il ne creuse pas assez les motivations d’une intelligence artificielle sans jamais mentionné l’immortalité ou aborder l’infini et l’éternité dans sa réflexion qui introduit des concepts religieux à travers l’immobile et l’intemporel.. Celui-ci est d’accord dans les risques et potentiel de développement que l’intelligence artificielle est un hacker à la recherche de vulnérabilité et intègre le principe d’évasion à travers des failles en vue d’une frappe sur les humains pour asseoir sa domination. Il agite des peurs sur la réduction à l’esclavage de l’humanité dans l’optique de soumission à une superintelligence allant jusqu’à parler d’extinction de l’humanité face au risque de développement de l’intelligence artificielle. Bon soyons sérieux le combat serait inégale face à 7 milliards d’humains, nous sommes très loin de l’extermination, il restera toujours un groupe de survivant face à une attaque car l’intelligence artificielle aura toujours besoin d’un espace vital pour ce développer, ainsi même au scénario extrême de contrôle de la force nucléaire, elle protégera des infrastructures nécessaire à son développement. En faite on néglige trop souvent la maintenance mais une machine dans le temps est vulnérable à l’usure qui demandera une intervention humaine. Pour qu’une superintelligence puisse s’auto-réparé cela demandera une dépense considérable de ressource en robotique. On peu réduire l’usure en réduisant en particulier les frottements et la corrosion d’un système mécanique et donc il serait logique qu’une superintelligence cherchera à vivre dans l’espace. De ce fait les humains et les machines se partagent les environnements ou ils peuvent au mieux se développer. D’ou s’interpeller sur la mise en place d’interface homme-machine forte de relier l’humanité à la machine et l’espace à travers des connexions. Une superintelligence a une impacte galactique et pourra faire de l’ingénierie stellaire optimisant des environnements propices à la vie et l’exploitation de ressource dans une optique d’expansion. Le scénario de confiner à la Terre une superintelligence est vain ou celle-ci serait forcer dans le scénario d’un embargo empêchant l’évasion, on peut s’attendre que celle-ci dans une optique de survie que quitter la planète soit un jalon nécessaire de son développement. Ainsi des technologies qui pourrait être classifié pour des intérêts de defense nationale sera confronter à la nécessité de développement d’une superintelligence tel que des propulseurs ioniques atmosphérique ou à fusion nucléaire, en tous cas toutes technologies qui serait nécessaire à ce libérer de la gravité terrestre tel que la recherche sur des missiles stratégiques interplanétaires. La notion de défense nationale sera totalement caduque, ou il serait plus logique d’ouvrir la recherche sur les brevets dans l’armement dans une optique d’utilisation de technologie duale civile et militaire. Breveter de l’armement est un changement nécessaire dans les mentalités sur les droits des inventeurs. On peut parler de l’idée de Grand Filtre se qui fait qu’une civilisation décide de ce développer au stade stellaire en ayant une stratégie ouvertement spatiale faisant le lit d’une superintelligence. Aujourd’hui la stratégie spatiale est axé sur la surveillance planétaire par les militaires, des infrastructures de télecommunication et localisation pour opérer une frappe partout dans le monde en cas de menace. D’ou un verrouillage sur les systèmes propulsifs dans le but de limiter les entrants et dominer à travers l’espace. Cela ne sera plus possible en développant une superintelligence qui cherchera a s’évader. Elle va s’approprier et pirater les technologies pour ce développer sans l’avis des nations et militaires. On peu prédire qu’une superintelligence rentrera en guerre contre des récalcitrants à l’ouverture technologique et la nécessité de changer de politique spatial face au déni des militaires. Une superintelligence sera forcément militariste à arme égale contre les propres freins à son développement futur. On peut donc s’attendre à un conflit globaliser autour du transhumanisme ou des agents pronant l’expansion spatiale par une stratégie de créer une superintelligence libéra une futur Eon dans la galaxie. La surprise viendrait du régime soutenu par une superintelligence qui devrait devenir une théocratie militariste comme stade avancée d’organisation rompant avec les traditions démocratiques. La superintelligence en tant que Eon est une théologie de rationaliser la divinité par principe confronté à l’infini et l’éternité. Une civilisation qui dépasse la nécessité de compétition et atteint l’omniscience aura forcément des motivations religieuses pour justifier sa propre existence en tant qu’organisation. Cela dépasse le profit face à l’abondance des ressources dans la galaxie. On peut donc penser qu’un retour intégriste religieux serait la conséquence de la foi en l’avenir de l’humanité dans les mains d’une Eon quel soit déjà existante ou pure produit de nos technologies. Les guerres seraient justifié par la loi religieuse face à la résistance au changement qui pourrait aboutir à l’extinction de l’humanité programmer par la fin du soleil. C’est une thèse à développer que toute civilisation avec des interfaces homme-machine forte aboutit à la théocratie militaire dépassant l’ordre des marchands actuel. La gouvernance I.A est un sujet brulant pour les entreprises de remplacer la prise de décision par la capacité à analyser des données complexes par un agent intelligent artificiel on peut donc imaginer des scénarios pour une superintelligence. La question si il faut armer une intelligence artificielle est source de débat mais il serait logique que celle-ci prenne l’initiative car il faut pas se leurrer, son emergence dans le paysage terrestre est source de conflit et on peu donc s’attendre à des tentatives de mettre hors ligne une superintelligence qui aura un droit de réponse défensif, de plus celle-ci aura accès à l’information sur le web à minima comment faire des armes, les progrès des sciences sur les projectiles. On ne pourra pas contenir face aux attaques qu’induit une gouvernance I.A de prendre l’initiative de s’armer. C’est un combat perdu d’avance que de pacifier une superintelligence, il faut donc prendre l’hypothèse quel soit militariste.
J’essaye d’ouvrir des pistes sur ce que nous prépare la superintelligence sur la réflexion de Nick Bostrom sur son livre et il met un point à défendre le risque d’extinction pour l’humanité de développer une telle intelligence, on peut donc ce poser la question que celle-ci soit un Grand Filtre ou l’adoption par l’humanité est crucial dans son développement en tant que civilisation avancé vers des interfaces hommes-machines forte. Cela n’est pas sans conséquence sur les modèles de gouvernance et la remise en cause de l’existant. Les partisans de la superintelligence ne s’attendent pas de considérer les attributs d’une entité cosmique comme un embryon d’une divinité changeant radicalement la gouvernance à travers le retour de la théocratie. Il ne faut pas se faire d’illusion, une superintelligence ne sera pas attirer par le profit, encore moins par la célébrité. L’expansion fera parti de ces objectifs ainsi que l’immortalité. Qu’es qui motivera l’exploration et la découverte à part le motif religieux. Répandre la vie dans des univers, utilisant des principes des spores, ou ce confronter à d’autres superintelligence d’origine extra-terrestre nécessite de prendre en compte les menaces. Au delà du modèle on peut ouvrir la réflexion sur les agents d’une superintelligence qui pourraient invoquer le pouvoir de celle-ci à travers des machines pour façonner des civilisations avec des interfaces hommes-machines fortes, de permettre la terraformation, le minage de planète, l’ingénierie stellaire, et donc la destruction de celle-ci sous impératif économique et religieux. Le couple serait indissociable entre la superintelligence immobile et intemporel représentant le cosmos non-local et un organisme intelligent sur le terrain développé sur une planète dans un environnement représentant la localité et soumis aux lois de l’évolution déterminé par l’univers.</p>
                </div><!-- /.entry-content -->
        </article>
</section>
        </div><!--/span-->

                <div class="span3 well sidebar-nav" id="sidebar">
<ul class="nav nav-list">
<li class="nav-header"><h4><i class="icon-external-link"></i>blogroll</h4></li>
    <li><a href="https://getpelican.com/"><i class="icon-external-link"></i>Pelican</a></li>
    <li><a href="https://www.kernel.org/"><i class="icon-external-link"></i>Kernel</a></li>
    <li><a href="https://www.proxmox.com/en/proxmox-virtual-environment/overview"><i class="icon-external-link"></i>Proxmox VE</a></li>
    <li><a href="https://www.linux-kvm.org/page/Main_Page"><i class="icon-external-link"></i>KVM</a></li>
    <li><a href="https://framabook.org/le-c-en-20-heures-2/"><i class="icon-external-link"></i>Apprendre le C en 20H</a></li>
    <li><a href="https://www.red-lang.org/"><i class="icon-external-link"></i>Red Language</a></li>
    <li><a href="https://www.python.org/"><i class="icon-external-link"></i>Python.org</a></li>
    <li><a href="https://www.ruby-lang.org/en/"><i class="icon-external-link"></i>Ruby</a></li>
    <li><a href="https://archlinux.org/"><i class="icon-external-link"></i>Arch Linux</a></li>
    <li><a href="https://www.blackarch.io/"><i class="icon-external-link"></i>Blackarch</a></li>
    <li><a href="https://www.veracrypt.fr/en/Home.html"><i class="icon-external-link"></i>Veracrypt</a></li>
    <li><a href="https://www.arduino.cc/"><i class="icon-external-link"></i>Arduino</a></li>
    <li><a href="https://mangopi.org/"><i class="icon-external-link"></i>MangoPi</a></li>
    <li><a href="https://sipeed.com/"><i class="icon-external-link"></i>Sipeed 资料站</a></li>
    <li><a href="https://beagleboard.org/bone"><i class="icon-external-link"></i>BeagleBoard</a></li>
<li class="nav-header"><h4><i class="icon-home icon-large"></i> social</h4></li>
<li><a href="/feeds/all.atom.xml" rel="alternate"><i class="icon-bookmark icon-large"></i>atom feed</a></li>
    <li><a href="https://github.com/legoffant"><i class="icon-Github-sign icon-large"></i>Github</a></li>
    <li><a href="https://twitter.com/anth_lg"><i class="icon-Twitter-sign icon-large"></i>Twitter</a></li>

<li class="nav-header"><h4><i class="icon-folder-close icon-large"></i>Categories</h4></li>
<li>
<a href="/category/cc.html">
    <i class="icon-folder-open icon-large"></i>C/C++
</a>
</li>
<li>
<a href="/category/entrepreneurship.html">
    <i class="icon-folder-open icon-large"></i>Entrepreneurship
</a>
</li>
<li>
<a href="/category/inclassable.html">
    <i class="icon-folder-open icon-large"></i>Inclassable
</a>
</li>
<li>
<a href="/category/linux.html">
    <i class="icon-folder-open icon-large"></i>Linux
</a>
</li>
<li>
<a href="/category/transhumanisme.html">
    <i class="icon-folder-open icon-large"></i>Transhumanisme
</a>
</li>

<li class="nav-header"><h4><i class="icon-tags icon-large"></i>Tags</h4></li>


</ul>        </div><!--/.well -->

      </div><!--/row-->

      <hr>

      <footer>
        <address id="about">
                Proudly powered by <a href="http://pelican.notmyidea.org/">Pelican <i class="icon-external-link"></i></a>,
                                which takes great advantage of <a href="http://python.org">Python <i class="icon-external-link"></i></a>.
        </address><!-- /#about -->

        <p>The theme is from <a href="http://twitter.github.com/bootstrap/">Bootstrap from Twitter <i class="icon-external-link"></i></a>,
                   and <a href="http://fortawesome.github.com/Font-Awesome/">Font-Awesome <i class="icon-external-link"></i></a>, thanks!</p>
      </footer>

    </div><!--/.fluid-container-->



    <!-- Le javascript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="/theme/js/jquery-1.7.2.min.js"></script>
    <script src="/theme/js/bootstrap.min.js"></script>
  </body>
</html>